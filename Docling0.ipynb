{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install Docling"
      ],
      "metadata": {
        "id": "s58rD_UZExCZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yXHPTYkjEQiu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Dict, List, Any, Optional\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling_core.types.doc import DoclingDocument, NodeItem, TextItem, TableItem, PictureItem\n",
        "\n",
        "\n",
        "class DoclingHierarchyMapper:\n",
        "    \"\"\"\n",
        "    Creates AWS Textract-like hierarchical mapping from Docling documents.\n",
        "    Maps sections -> subsections -> paragraphs with relationship tracking.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.converter = DocumentConverter()\n",
        "        self.hierarchy_map = {}\n",
        "        self.element_counter = 0\n",
        "\n",
        "    def convert_document(self, source: str) -> DoclingDocument:\n",
        "        \"\"\"Convert document using Docling\"\"\"\n",
        "        result = self.converter.convert(source)\n",
        "        return result.document\n",
        "\n",
        "    def generate_element_id(self, element_type: str) -> str:\n",
        "        \"\"\"Generate unique element ID\"\"\"\n",
        "        self.element_counter += 1\n",
        "        return f\"{element_type}_{self.element_counter:04d}\"\n",
        "\n",
        "    def extract_hierarchy_mapping(self, document: DoclingDocument) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Extract hierarchical mapping from DoclingDocument.\n",
        "        Returns AWS Textract-like structure with sections, subsections, and paragraphs.\n",
        "        \"\"\"\n",
        "        self.hierarchy_map = {\n",
        "            \"document_metadata\": self._extract_document_metadata(document),\n",
        "            \"sections\": [],\n",
        "            \"element_relationships\": {},\n",
        "            \"content_summary\": {\n",
        "                \"total_sections\": 0,\n",
        "                \"total_subsections\": 0,\n",
        "                \"total_paragraphs\": 0,\n",
        "                \"total_tables\": 0,\n",
        "                \"total_images\": 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Debug: Print document structure\n",
        "        print(f\"Document has body: {document.body is not None}\")\n",
        "        if document.body:\n",
        "            print(f\"Body has children: {hasattr(document.body, 'children')}\")\n",
        "            if hasattr(document.body, 'children'):\n",
        "                print(f\"Number of body children: {len(document.body.children)}\")\n",
        "\n",
        "        # Process the document body structure\n",
        "        if document.body:\n",
        "            self._process_body_structure(document, document.body)\n",
        "\n",
        "        # If no sections found from body, try processing all text items directly\n",
        "        if not self.hierarchy_map[\"sections\"]:\n",
        "            print(\"No sections found in body, trying direct text processing...\")\n",
        "            self._process_text_items_directly(document)\n",
        "\n",
        "        # Process tables separately\n",
        "        self._process_tables(document)\n",
        "\n",
        "        # Process images separately\n",
        "        self._process_images(document)\n",
        "\n",
        "        # Update summary counts\n",
        "        self._update_content_summary()\n",
        "\n",
        "        return self.hierarchy_map\n",
        "\n",
        "    def _extract_document_metadata(self, document: DoclingDocument) -> Dict[str, Any]:\n",
        "        \"\"\"Extract document-level metadata\"\"\"\n",
        "        metadata = {\n",
        "            \"page_count\": len(document.pages) if document.pages else 0,\n",
        "            \"total_text_items\": len(document.texts),\n",
        "            \"total_tables\": len(document.tables),\n",
        "            \"total_pictures\": len(document.pictures),\n",
        "            \"document_type\": \"multi_format_document\"\n",
        "        }\n",
        "\n",
        "        # Add origin information if available\n",
        "        if hasattr(document, 'origin') and document.origin:\n",
        "            metadata[\"source\"] = document.origin.filename if hasattr(document.origin, 'filename') else str(document.origin)\n",
        "\n",
        "        return metadata\n",
        "\n",
        "    def _process_body_structure(self, document: DoclingDocument, body_node: NodeItem, parent_id: str = None, level: int = 0):\n",
        "        \"\"\"Process the document body structure recursively\"\"\"\n",
        "        if not body_node or not hasattr(body_node, 'children'):\n",
        "            return\n",
        "\n",
        "        current_section = None\n",
        "\n",
        "        for child_ref in body_node.children:\n",
        "            try:\n",
        "                child_item = self._resolve_reference(document, child_ref)\n",
        "\n",
        "                if child_item and hasattr(child_item, 'label'):\n",
        "                    item_type = self._classify_item_type(child_item)\n",
        "\n",
        "                    if item_type == \"section_heading\":\n",
        "                        current_section = self._create_section(child_item, parent_id, level)\n",
        "                        self.hierarchy_map[\"sections\"].append(current_section)\n",
        "\n",
        "                        # Process children of this section\n",
        "                        if hasattr(child_item, 'children') and child_item.children:\n",
        "                            self._process_section_children(document, child_item, current_section[\"id\"], level + 1)\n",
        "\n",
        "                    elif item_type == \"paragraph\" and current_section:\n",
        "                        paragraph = self._create_paragraph(child_item, current_section[\"id\"])\n",
        "                        current_section[\"paragraphs\"].append(paragraph)\n",
        "                        self._add_relationship(current_section[\"id\"], paragraph[\"id\"], \"contains\")\n",
        "\n",
        "                    elif item_type == \"list\" and current_section:\n",
        "                        list_item = self._create_list_item(child_item, current_section[\"id\"])\n",
        "                        current_section[\"lists\"].append(list_item)\n",
        "                        self._add_relationship(current_section[\"id\"], list_item[\"id\"], \"contains\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing child reference {child_ref}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def _process_text_items_directly(self, document: DoclingDocument):\n",
        "        \"\"\"Process text items directly when no body structure is found\"\"\"\n",
        "        current_section = None\n",
        "\n",
        "        for i, text_item in enumerate(document.texts):\n",
        "            item_type = self._classify_item_type(text_item)\n",
        "\n",
        "            if item_type == \"section_heading\":\n",
        "                current_section = self._create_section(text_item, None, 0)\n",
        "                self.hierarchy_map[\"sections\"].append(current_section)\n",
        "\n",
        "            elif item_type == \"paragraph\":\n",
        "                if current_section is None:\n",
        "                    # Create a default section if none exists\n",
        "                    default_section = {\n",
        "                        \"id\": self.generate_element_id(\"section\"),\n",
        "                        \"type\": \"section\",\n",
        "                        \"level\": 0,\n",
        "                        \"title\": \"Document Content\",\n",
        "                        \"parent_id\": None,\n",
        "                        \"subsections\": [],\n",
        "                        \"paragraphs\": [],\n",
        "                        \"lists\": [],\n",
        "                        \"tables\": [],\n",
        "                        \"images\": [],\n",
        "                        \"bounding_box\": None,\n",
        "                        \"metadata\": {\n",
        "                            \"item_type\": \"default\",\n",
        "                            \"page_number\": None\n",
        "                        }\n",
        "                    }\n",
        "                    self.hierarchy_map[\"sections\"].append(default_section)\n",
        "                    current_section = default_section\n",
        "\n",
        "                paragraph = self._create_paragraph(text_item, current_section[\"id\"])\n",
        "                current_section[\"paragraphs\"].append(paragraph)\n",
        "                self._add_relationship(current_section[\"id\"], paragraph[\"id\"], \"contains\")\n",
        "\n",
        "    def _process_section_children(self, document: DoclingDocument, section_node: NodeItem, parent_section_id: str, level: int):\n",
        "        \"\"\"Process children of a section node\"\"\"\n",
        "        if not hasattr(section_node, 'children'):\n",
        "            return\n",
        "\n",
        "        for child_ref in section_node.children:\n",
        "            try:\n",
        "                child_item = self._resolve_reference(document, child_ref)\n",
        "\n",
        "                if child_item:\n",
        "                    item_type = self._classify_item_type(child_item)\n",
        "\n",
        "                    if item_type == \"section_heading\":\n",
        "                        # This is a subsection\n",
        "                        subsection = self._create_section(child_item, parent_section_id, level)\n",
        "\n",
        "                        # Find parent section and add subsection\n",
        "                        parent_section = self._find_section_by_id(parent_section_id)\n",
        "                        if parent_section:\n",
        "                            parent_section[\"subsections\"].append(subsection)\n",
        "                            self._add_relationship(parent_section_id, subsection[\"id\"], \"contains\")\n",
        "\n",
        "                        # Process subsection children\n",
        "                        if hasattr(child_item, 'children') and child_item.children:\n",
        "                            self._process_section_children(document, child_item, subsection[\"id\"], level + 1)\n",
        "\n",
        "                    elif item_type == \"paragraph\":\n",
        "                        paragraph = self._create_paragraph(child_item, parent_section_id)\n",
        "                        parent_section = self._find_section_by_id(parent_section_id)\n",
        "                        if parent_section:\n",
        "                            parent_section[\"paragraphs\"].append(paragraph)\n",
        "                            self._add_relationship(parent_section_id, paragraph[\"id\"], \"contains\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing section child {child_ref}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def _classify_item_type(self, item) -> str:\n",
        "        \"\"\"Classify the type of document item\"\"\"\n",
        "        if hasattr(item, 'label'):\n",
        "            label = item.label.lower()\n",
        "            # More comprehensive heading detection\n",
        "            if any(heading in label for heading in ['title', 'heading', 'section', 'header', 'caption']):\n",
        "                return \"section_heading\"\n",
        "            elif any(list_word in label for list_word in ['list', 'item', 'bullet']):\n",
        "                return \"list\"\n",
        "            elif any(para in label for para in ['paragraph', 'text', 'body']):\n",
        "                return \"paragraph\"\n",
        "\n",
        "        # Default classification based on content\n",
        "        if hasattr(item, 'text') and item.text:\n",
        "            text = item.text.strip()\n",
        "            text_length = len(text)\n",
        "\n",
        "            # Heuristics for section headings\n",
        "            if text_length < 200 and text_length > 0:\n",
        "                # Check if it looks like a heading\n",
        "                lines = text.split('\\n')\n",
        "                if len(lines) <= 2:  # Short, likely a heading\n",
        "                    # Additional checks for heading characteristics\n",
        "                    if (text.isupper() or\n",
        "                        any(char.isdigit() for char in text[:10]) or  # Starts with numbers\n",
        "                        text.endswith(':') or\n",
        "                        len(text.split()) <= 10):  # Short phrases\n",
        "                        return \"section_heading\"\n",
        "\n",
        "            return \"paragraph\"\n",
        "\n",
        "        return \"unknown\"\n",
        "\n",
        "    def _create_section(self, item, parent_id: str, level: int) -> Dict[str, Any]:\n",
        "        \"\"\"Create a section dictionary\"\"\"\n",
        "        section_id = self.generate_element_id(\"section\")\n",
        "\n",
        "        section = {\n",
        "            \"id\": section_id,\n",
        "            \"type\": \"section\",\n",
        "            \"level\": level,\n",
        "            \"title\": item.text if hasattr(item, 'text') else \"\",\n",
        "            \"parent_id\": parent_id,\n",
        "            \"subsections\": [],\n",
        "            \"paragraphs\": [],\n",
        "            \"lists\": [],\n",
        "            \"tables\": [],\n",
        "            \"images\": [],\n",
        "            \"bounding_box\": self._extract_bounding_box(item),\n",
        "            \"metadata\": {\n",
        "                \"item_type\": item.label if hasattr(item, 'label') else \"unknown\",\n",
        "                \"page_number\": self._get_page_number(item)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return section\n",
        "\n",
        "    def _create_paragraph(self, item, parent_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"Create a paragraph dictionary\"\"\"\n",
        "        paragraph_id = self.generate_element_id(\"paragraph\")\n",
        "\n",
        "        paragraph = {\n",
        "            \"id\": paragraph_id,\n",
        "            \"type\": \"paragraph\",\n",
        "            \"parent_id\": parent_id,\n",
        "            \"text\": item.text if hasattr(item, 'text') else \"\",\n",
        "            \"bounding_box\": self._extract_bounding_box(item),\n",
        "            \"metadata\": {\n",
        "                \"item_type\": item.label if hasattr(item, 'label') else \"unknown\",\n",
        "                \"page_number\": self._get_page_number(item),\n",
        "                \"word_count\": len(item.text.split()) if hasattr(item, 'text') and item.text else 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return paragraph\n",
        "\n",
        "    def _create_list_item(self, item, parent_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"Create a list item dictionary\"\"\"\n",
        "        list_id = self.generate_element_id(\"list\")\n",
        "\n",
        "        list_item = {\n",
        "            \"id\": list_id,\n",
        "            \"type\": \"list\",\n",
        "            \"parent_id\": parent_id,\n",
        "            \"items\": [],\n",
        "            \"bounding_box\": self._extract_bounding_box(item),\n",
        "            \"metadata\": {\n",
        "                \"item_type\": item.label if hasattr(item, 'label') else \"unknown\",\n",
        "                \"page_number\": self._get_page_number(item)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return list_item\n",
        "\n",
        "    def _process_tables(self, document: DoclingDocument):\n",
        "        \"\"\"Process tables in the document\"\"\"\n",
        "        for table in document.tables:\n",
        "            table_id = self.generate_element_id(\"table\")\n",
        "\n",
        "            table_data = {\n",
        "                \"id\": table_id,\n",
        "                \"type\": \"table\",\n",
        "                \"rows\": [],\n",
        "                \"columns\": [],\n",
        "                \"bounding_box\": self._extract_bounding_box(table),\n",
        "                \"metadata\": {\n",
        "                    \"page_number\": self._get_page_number(table)\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Extract table structure if available\n",
        "            if hasattr(table, 'data') and table.data:\n",
        "                table_data[\"rows\"] = self._extract_table_rows(table.data)\n",
        "\n",
        "            # Try to associate table with nearest section\n",
        "            nearest_section = self._find_nearest_section(table)\n",
        "            if nearest_section:\n",
        "                nearest_section[\"tables\"].append(table_data)\n",
        "                self._add_relationship(nearest_section[\"id\"], table_id, \"contains\")\n",
        "\n",
        "    def _process_images(self, document: DoclingDocument):\n",
        "        \"\"\"Process images in the document\"\"\"\n",
        "        for image in document.pictures:\n",
        "            image_id = self.generate_element_id(\"image\")\n",
        "\n",
        "            image_data = {\n",
        "                \"id\": image_id,\n",
        "                \"type\": \"image\",\n",
        "                \"bounding_box\": self._extract_bounding_box(image),\n",
        "                \"metadata\": {\n",
        "                    \"page_number\": self._get_page_number(image)\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Try to associate image with nearest section\n",
        "            nearest_section = self._find_nearest_section(image)\n",
        "            if nearest_section:\n",
        "                nearest_section[\"images\"].append(image_data)\n",
        "                self._add_relationship(nearest_section[\"id\"], image_id, \"contains\")\n",
        "\n",
        "    def _extract_bounding_box(self, item) -> Optional[Dict[str, float]]:\n",
        "        \"\"\"Extract bounding box information if available\"\"\"\n",
        "        if hasattr(item, 'bbox') and item.bbox:\n",
        "            return {\n",
        "                \"left\": item.bbox.l,\n",
        "                \"top\": item.bbox.t,\n",
        "                \"width\": item.bbox.w,\n",
        "                \"height\": item.bbox.h\n",
        "            }\n",
        "        return None\n",
        "\n",
        "    def _get_page_number(self, item) -> Optional[int]:\n",
        "        \"\"\"Get page number for an item\"\"\"\n",
        "        if hasattr(item, 'prov') and item.prov:\n",
        "            for prov in item.prov:\n",
        "                if hasattr(prov, 'page_no'):\n",
        "                    return prov.page_no\n",
        "        return None\n",
        "\n",
        "    def _extract_table_rows(self, table_data) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Extract table rows from table data\"\"\"\n",
        "        rows = []\n",
        "        if hasattr(table_data, 'table_cells'):\n",
        "            # Group cells by row\n",
        "            row_groups = {}\n",
        "            for cell in table_data.table_cells:\n",
        "                row_idx = cell.row_idx if hasattr(cell, 'row_idx') else 0\n",
        "                if row_idx not in row_groups:\n",
        "                    row_groups[row_idx] = []\n",
        "                row_groups[row_idx].append({\n",
        "                    \"text\": cell.text if hasattr(cell, 'text') else \"\",\n",
        "                    \"column_idx\": cell.col_idx if hasattr(cell, 'col_idx') else 0\n",
        "                })\n",
        "\n",
        "            # Convert to list of rows\n",
        "            for row_idx in sorted(row_groups.keys()):\n",
        "                rows.append({\n",
        "                    \"row_idx\": row_idx,\n",
        "                    \"cells\": sorted(row_groups[row_idx], key=lambda x: x['column_idx'])\n",
        "                })\n",
        "\n",
        "        return rows\n",
        "\n",
        "    def _resolve_reference(self, document: DoclingDocument, ref):\n",
        "        \"\"\"Resolve a JSON pointer reference to an actual item\"\"\"\n",
        "        try:\n",
        "            # Handle different types of references\n",
        "            if hasattr(ref, 'ref'):\n",
        "                # This is a RefItem object, get the actual reference string\n",
        "                ref_str = ref.ref\n",
        "            elif isinstance(ref, str):\n",
        "                # This is already a string reference\n",
        "                ref_str = ref\n",
        "            else:\n",
        "                # Try to convert to string\n",
        "                ref_str = str(ref)\n",
        "\n",
        "            # Parse JSON pointer (e.g., \"#/texts/0\")\n",
        "            if ref_str.startswith('#/'):\n",
        "                parts = ref_str[2:].split('/')  # Remove '#/' and split\n",
        "            else:\n",
        "                parts = ref_str.split('/')\n",
        "\n",
        "            if len(parts) >= 2:\n",
        "                collection_name = parts[0]\n",
        "                try:\n",
        "                    index = int(parts[1])\n",
        "                except ValueError:\n",
        "                    print(f\"Warning: Could not resolve reference {ref_str}: invalid literal for int() with base 10: '{parts[1]}'\")\n",
        "                    return None\n",
        "\n",
        "                if collection_name == 'texts' and index < len(document.texts):\n",
        "                    return document.texts[index]\n",
        "                elif collection_name == 'tables' and index < len(document.tables):\n",
        "                    return document.tables[index]\n",
        "                elif collection_name == 'pictures' and index < len(document.pictures):\n",
        "                    return document.pictures[index]\n",
        "                elif collection_name == 'groups' and hasattr(document, 'groups') and index < len(document.groups):\n",
        "                    return document.groups[index]\n",
        "                else:\n",
        "                    print(f\"Warning: Reference {ref_str} points to non-existent item\")\n",
        "\n",
        "        except (ValueError, IndexError, AttributeError) as e:\n",
        "            print(f\"Warning: Could not resolve reference {ref}: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _find_section_by_id(self, section_id: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Find a section by ID in the hierarchy\"\"\"\n",
        "        def search_sections(sections):\n",
        "            for section in sections:\n",
        "                if section[\"id\"] == section_id:\n",
        "                    return section\n",
        "                # Search in subsections\n",
        "                found = search_sections(section[\"subsections\"])\n",
        "                if found:\n",
        "                    return found\n",
        "            return None\n",
        "\n",
        "        return search_sections(self.hierarchy_map[\"sections\"])\n",
        "\n",
        "    def _find_nearest_section(self, item) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Find the nearest section for an item (simplified heuristic)\"\"\"\n",
        "        # This is a simplified implementation\n",
        "        # In practice, you'd use spatial relationships and page positioning\n",
        "        if self.hierarchy_map[\"sections\"]:\n",
        "            return self.hierarchy_map[\"sections\"][-1]  # Return last section for now\n",
        "        return None\n",
        "\n",
        "    def _add_relationship(self, parent_id: str, child_id: str, relationship_type: str):\n",
        "        \"\"\"Add a relationship between elements\"\"\"\n",
        "        if parent_id not in self.hierarchy_map[\"element_relationships\"]:\n",
        "            self.hierarchy_map[\"element_relationships\"][parent_id] = []\n",
        "\n",
        "        self.hierarchy_map[\"element_relationships\"][parent_id].append({\n",
        "            \"child_id\": child_id,\n",
        "            \"relationship\": relationship_type\n",
        "        })\n",
        "\n",
        "    def _update_content_summary(self):\n",
        "        \"\"\"Update content summary counts\"\"\"\n",
        "        def count_elements(sections):\n",
        "            section_count = len(sections)\n",
        "            subsection_count = 0\n",
        "            paragraph_count = 0\n",
        "            table_count = 0\n",
        "            image_count = 0\n",
        "\n",
        "            for section in sections:\n",
        "                subsection_count += len(section[\"subsections\"])\n",
        "                paragraph_count += len(section[\"paragraphs\"])\n",
        "                table_count += len(section[\"tables\"])\n",
        "                image_count += len(section[\"images\"])\n",
        "\n",
        "                # Recursively count subsections\n",
        "                sub_counts = count_elements(section[\"subsections\"])\n",
        "                subsection_count += sub_counts[1]\n",
        "                paragraph_count += sub_counts[2]\n",
        "                table_count += sub_counts[3]\n",
        "                image_count += sub_counts[4]\n",
        "\n",
        "            return section_count, subsection_count, paragraph_count, table_count, image_count\n",
        "\n",
        "        counts = count_elements(self.hierarchy_map[\"sections\"])\n",
        "        self.hierarchy_map[\"content_summary\"].update({\n",
        "            \"total_sections\": counts[0],\n",
        "            \"total_subsections\": counts[1],\n",
        "            \"total_paragraphs\": counts[2],\n",
        "            \"total_tables\": counts[3],\n",
        "            \"total_images\": counts[4]\n",
        "        })\n",
        "\n",
        "    def get_section_tree(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get a simplified section tree view\"\"\"\n",
        "        def build_tree(sections):\n",
        "            tree = {}\n",
        "            for section in sections:\n",
        "                tree[section[\"title\"]] = {\n",
        "                    \"id\": section[\"id\"],\n",
        "                    \"level\": section[\"level\"],\n",
        "                    \"paragraph_count\": len(section[\"paragraphs\"]),\n",
        "                    \"subsections\": build_tree(section[\"subsections\"])\n",
        "                }\n",
        "            return tree\n",
        "\n",
        "        return build_tree(self.hierarchy_map[\"sections\"])\n",
        "\n",
        "    def export_to_json(self, filepath: str):\n",
        "        \"\"\"Export hierarchy mapping to JSON file\"\"\"\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.hierarchy_map, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    def print_hierarchy_summary(self):\n",
        "        \"\"\"Print a summary of the document hierarchy\"\"\"\n",
        "        print(\"Document Hierarchy Summary:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        summary = self.hierarchy_map[\"content_summary\"]\n",
        "        print(f\"Total Sections: {summary['total_sections']}\")\n",
        "        print(f\"Total Subsections: {summary['total_subsections']}\")\n",
        "        print(f\"Total Paragraphs: {summary['total_paragraphs']}\")\n",
        "        print(f\"Total Tables: {summary['total_tables']}\")\n",
        "        print(f\"Total Images: {summary['total_images']}\")\n",
        "\n",
        "        print(\"\\nSection Structure:\")\n",
        "        tree = self.get_section_tree()\n",
        "        self._print_tree(tree, 0)\n",
        "\n",
        "    def _print_tree(self, tree, level):\n",
        "        \"\"\"Print tree structure with indentation\"\"\"\n",
        "        for title, data in tree.items():\n",
        "            indent = \"  \" * level\n",
        "            print(f\"{indent}- {title} (ID: {data['id']}, Paragraphs: {data['paragraph_count']})\")\n",
        "            if data['subsections']:\n",
        "                self._print_tree(data['subsections'], level + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage and debugging\n",
        "def main():\n",
        "    # Initialize the mapper\n",
        "    mapper = DoclingHierarchyMapper()\n",
        "\n",
        "    # Convert a document (can be PDF, DOCX, etc.)\n",
        "    document_path = \"Contract document.pdf\"  # Replace with actual path\n",
        "\n",
        "    try:\n",
        "        # Convert document\n",
        "        document = mapper.convert_document(document_path)\n",
        "\n",
        "        # Debug information\n",
        "        print(\"=== DEBUG INFORMATION ===\")\n",
        "        print(f\"Document texts count: {len(document.texts)}\")\n",
        "        print(f\"Document tables count: {len(document.tables)}\")\n",
        "        print(f\"Document pictures count: {len(document.pictures)}\")\n",
        "\n",
        "        # Sample first few text items\n",
        "        print(\"\\nFirst 5 text items:\")\n",
        "        for i, text_item in enumerate(document.texts[:5]):\n",
        "            print(f\"  {i}: {text_item.label if hasattr(text_item, 'label') else 'No label'} - {text_item.text[:100] if hasattr(text_item, 'text') else 'No text'}...\")\n",
        "\n",
        "        # Extract hierarchy mapping\n",
        "        hierarchy = mapper.extract_hierarchy_mapping(document)\n",
        "\n",
        "        # Print summary\n",
        "        mapper.print_hierarchy_summary()\n",
        "\n",
        "        # Export to JSON\n",
        "        mapper.export_to_json(\"document_hierarchy.json\")\n",
        "\n",
        "        # Example: Access specific elements\n",
        "        print(\"\\n=== RESULTS ===\")\n",
        "        if hierarchy[\"sections\"]:\n",
        "            first_section = hierarchy[\"sections\"][0]\n",
        "            print(f\"First section title: {first_section['title']}\")\n",
        "            print(f\"First section level: {first_section['level']}\")\n",
        "            print(f\"First section paragraphs: {len(first_section['paragraphs'])}\")\n",
        "            print(f\"First section subsections: {len(first_section['subsections'])}\")\n",
        "        else:\n",
        "            print(\"No sections found in document\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing document: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wa6ich5Eukn",
        "outputId": "239a8310-519f-45bf-86e3-54cd635109df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DEBUG INFORMATION ===\n",
            "Document texts count: 279\n",
            "Document tables count: 2\n",
            "Document pictures count: 0\n",
            "\n",
            "First 5 text items:\n",
            "  0: section_header - This draft agreement is subject to change/fine tuning before final award of the contract...\n",
            "  1: section_header - (Sample Contract Agreement)...\n",
            "  2: section_header - AGREEMENT FOR HALL OF RESIDENCE NO. - __...\n",
            "  3: text - THIS  AGREEMENT has  been  made  on  this  __ th day  of  October,  2012  at  IIT  Kanpur BETWEEN In...\n",
            "  4: text - AND M/s __________ registered under ________________________ and having it's office at _____________...\n",
            "Document has body: True\n",
            "Body has children: True\n",
            "Number of body children: 152\n",
            "Warning: Could not resolve reference cref='#/texts/0': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/1': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/2': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/3': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/0': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/5': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/6': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/7': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/8': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/9': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/10': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/11': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/12': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/1': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/17': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/18': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/2': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/groups/3': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/34': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/35': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/36': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/37': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/38': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/4': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/groups/5': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/50': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/51': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/6': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/60': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/61': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/62': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/63': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/64': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/7': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/79': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/80': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/8': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/88': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/89': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/9': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/tables/0': invalid literal for int() with base 10: 'tables'\n",
            "Warning: Could not resolve reference cref='#/texts/93': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/10': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/104': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/11': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/111': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/112': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/113': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/114': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/12': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/120': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/121': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/13': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/129': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/130': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/14': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/136': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/137': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/138': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/15': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/148': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/149': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/16': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/151': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/152': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/153': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/154': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/155': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/156': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/157': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/158': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/159': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/160': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/161': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/162': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/163': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/164': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/tables/1': invalid literal for int() with base 10: 'tables'\n",
            "Warning: Could not resolve reference cref='#/texts/165': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/166': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/167': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/17': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/173': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/174': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/18': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/182': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/183': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/184': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/185': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/186': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/187': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/188': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/189': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/19': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/193': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/20': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/195': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/196': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/197': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/198': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/199': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/200': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/201': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/202': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/203': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/204': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/205': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/206': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/207': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/208': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/209': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/210': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/211': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/212': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/213': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/214': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/215': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/216': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/217': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/218': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/219': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/220': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/221': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/222': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/223': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/224': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/225': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/226': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/227': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/228': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/229': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/21': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/236': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/237': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/238': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/239': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/22': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/246': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/247': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/248': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/249': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/250': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/251': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/23': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/253': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/254': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/255': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/24': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/269': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/texts/270': invalid literal for int() with base 10: 'texts'\n",
            "Warning: Could not resolve reference cref='#/groups/25': invalid literal for int() with base 10: 'groups'\n",
            "Warning: Could not resolve reference cref='#/texts/278': invalid literal for int() with base 10: 'texts'\n",
            "No sections found in body, trying direct text processing...\n",
            "Document Hierarchy Summary:\n",
            "--------------------------------------------------\n",
            "Total Sections: 69\n",
            "Total Subsections: 0\n",
            "Total Paragraphs: 72\n",
            "Total Tables: 2\n",
            "Total Images: 0\n",
            "\n",
            "Section Structure:\n",
            "- This draft agreement is subject to change/fine tuning before final award of the contract (ID: section_0001, Paragraphs: 0)\n",
            "- (Sample Contract Agreement) (ID: section_0002, Paragraphs: 0)\n",
            "- AGREEMENT FOR HALL OF RESIDENCE NO. - __ (ID: section_0003, Paragraphs: 4)\n",
            "- 2 (ID: section_0008, Paragraphs: 4)\n",
            "- NOW therefore it is hereby agreed as follows: (ID: section_0013, Paragraphs: 0)\n",
            "- 3 (ID: section_0014, Paragraphs: 13)\n",
            "- 4 (ID: section_0028, Paragraphs: 0)\n",
            "- GENERAL CONDITIONS OF THE CONTRACT FOR PROVIDIG OPERATIONAL SERVICES IN THE MESS OF HALL OF RESIDENCE NO.-__ (ID: section_0029, Paragraphs: 0)\n",
            "- ARTICLE-1 (ID: section_0030, Paragraphs: 0)\n",
            "- 1.0 Definition of terms: (ID: section_0031, Paragraphs: 1)\n",
            "- 5 (ID: section_0033, Paragraphs: 2)\n",
            "- 6 (ID: section_0036, Paragraphs: 0)\n",
            "- ARTICLE-2 (ID: section_0037, Paragraphs: 1)\n",
            "- 7 (ID: section_0039, Paragraphs: 0)\n",
            "- ARTICLE-3 (ID: section_0040, Paragraphs: 0)\n",
            "- 3.0    Scope of Work: (ID: section_0041, Paragraphs: 1)\n",
            "- 8 (ID: section_0043, Paragraphs: 1)\n",
            "- 9 (ID: section_0045, Paragraphs: 1)\n",
            "- 10 (ID: section_0047, Paragraphs: 0)\n",
            "- 11 (ID: section_0048, Paragraphs: 1)\n",
            "- 12 (ID: section_0050, Paragraphs: 0)\n",
            "- ARTICLE-4 (ID: section_0051, Paragraphs: 0)\n",
            "- 4.0 Employment of workmen by the Service provider (ID: section_0052, Paragraphs: 0)\n",
            "- 13 (ID: section_0053, Paragraphs: 1)\n",
            "- 14 (ID: section_0055, Paragraphs: 2)\n",
            "- 15 (ID: section_0058, Paragraphs: 0)\n",
            "- ARTICLE-5 (ID: section_0059, Paragraphs: 0)\n",
            "- 16 (ID: section_0060, Paragraphs: 2)\n",
            "- 17 (ID: section_0063, Paragraphs: 0)\n",
            "- ARTICLE-6 (ID: section_0064, Paragraphs: 0)\n",
            "- 6.0            General Instructions to the Service provider: (ID: section_0065, Paragraphs: 0)\n",
            "- 6.1 Security Deposit: (ID: section_0066, Paragraphs: 3)\n",
            "- 6.2 Termination: (ID: section_0070, Paragraphs: 2)\n",
            "- 6.3 Regarding compliance of statutory provisions: (ID: section_0073, Paragraphs: 1)\n",
            "- 18 (ID: section_0075, Paragraphs: 0)\n",
            "- 19 (ID: section_0076, Paragraphs: 1)\n",
            "- 6.5 Interpretation of Contract Documents : (ID: section_0078, Paragraphs: 0)\n",
            "- 20 (ID: section_0079, Paragraphs: 1)\n",
            "- 21 (ID: section_0081, Paragraphs: 0)\n",
            "- 6.6 Forfeiture of Security Deposit: (ID: section_0082, Paragraphs: 2)\n",
            "- 22 (ID: section_0085, Paragraphs: 0)\n",
            "- ARTICLE-7 (ID: section_0086, Paragraphs: 0)\n",
            "- 7.0 Service provider's Subordinate Staff and their Conduct: (ID: section_0087, Paragraphs: 2)\n",
            "- 23 (ID: section_0090, Paragraphs: 2)\n",
            "- 7.1 Sub-Letting of Works: (ID: section_0093, Paragraphs: 1)\n",
            "- 7.2 Power of Entry: (ID: section_0095, Paragraphs: 1)\n",
            "- 24 (ID: section_0097, Paragraphs: 1)\n",
            "- 7.3 Force Majeure: (ID: section_0099, Paragraphs: 4)\n",
            "- 7.4 Release of Information: (ID: section_0104, Paragraphs: 1)\n",
            "- 7.5 Completion of Contract: (ID: section_0106, Paragraphs: 1)\n",
            "- 7.6 Schedule of Rates and Payments: (ID: section_0108, Paragraphs: 1)\n",
            "- 25 (ID: section_0110, Paragraphs: 1)\n",
            "- 7.7 Schedule of Rates to be Inclusive: (ID: section_0112, Paragraphs: 1)\n",
            "- 7.8 Receipts for Payment: (ID: section_0114, Paragraphs: 1)\n",
            "- 7.9 Completion Certificate/No Dues Certificate (ID: section_0116, Paragraphs: 1)\n",
            "- 26 (ID: section_0118, Paragraphs: 1)\n",
            "- 7.10 Accident or Injury to Workman: (ID: section_0120, Paragraphs: 1)\n",
            "- 7.11 Damage to Property: (ID: section_0122, Paragraphs: 1)\n",
            "- 7.12 Labour Laws: (ID: section_0124, Paragraphs: 0)\n",
            "- 27 (ID: section_0125, Paragraphs: 0)\n",
            "- 7.13 Safety Regulations: (ID: section_0126, Paragraphs: 1)\n",
            "- 7.14 Arbitration: (ID: section_0128, Paragraphs: 0)\n",
            "- 7.15 Jurisdiction: (ID: section_0129, Paragraphs: 1)\n",
            "- 28 (ID: section_0131, Paragraphs: 1)\n",
            "- 7.16 General Rules: (ID: section_0133, Paragraphs: 2)\n",
            "- 29 (ID: section_0136, Paragraphs: 0)\n",
            "- Annexure-I (ID: section_0137, Paragraphs: 0)\n",
            "- MESS REBATE RULES (ID: section_0138, Paragraphs: 0)\n",
            "- 30 (ID: section_0139, Paragraphs: 2)\n",
            "\n",
            "=== RESULTS ===\n",
            "First section title: This draft agreement is subject to change/fine tuning before final award of the contract\n",
            "First section level: 0\n",
            "First section paragraphs: 0\n",
            "First section subsections: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tg2owe6GGSu",
        "outputId": "a512edec-52fd-4320-ac35-52db5dd70272"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Contract document.pdf'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R42SfmlkGG3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}